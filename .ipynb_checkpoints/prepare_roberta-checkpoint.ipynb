{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import listdir\n",
    "from pandas.errors import EmptyDataError\n",
    "from fairseq.models.roberta import RobertaModel, RobertaHubInterface\n",
    "from fairseq import hub_utils\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AGORA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First prepare data (finally output of it will go to another folder, data is too large for github)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wyborcza_articles = []\n",
    "for filename in listdir('data/wyborcza/articles'):\n",
    "    try:\n",
    "        wyborcza_articles.append(pd.read_csv('data/wyborcza/articles/'+filename, header = None))\n",
    "    except EmptyDataError:\n",
    "        pass # empty file\n",
    "wyborcza_articles = pd.concat(wyborcza_articles)\n",
    "wyborcza_articles.columns = ['url', 'title', 'short', 'long', 'img', 'com']\n",
    "wyborcza_articles['short'] = wyborcza_articles['short'].str.replace(r'(.|..)\\n', '')\n",
    "wyborcza_articles = wyborcza_articles[~wyborcza_articles['long'].str.contains('W odpowiedzi do @', na = False) == True]\n",
    "wyborcza_articles = wyborcza_articles[['title', 'short', 'long']]\n",
    "wyborcza_articles = wyborcza_articles.dropna()\n",
    "wyborcza_articles = wyborcza_articles[wyborcza_articles['title'].duplicated() == False]\n",
    "wyborcza_articles = wyborcza_articles[wyborcza_articles['short'] != '0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gazeta_articles = []\n",
    "for filename in listdir('data/gazeta/articles'):\n",
    "    try:\n",
    "        gazeta_articles.append(pd.read_csv('data/gazeta/articles/'+filename, header = None))\n",
    "    except EmptyDataError:\n",
    "        pass # empty file\n",
    "gazeta_articles = pd.concat(gazeta_articles)\n",
    "gazeta_articles.columns = ['url', 'title', 'short', 'long', 'img', 'com']\n",
    "gazeta_articles = gazeta_articles[['title', 'short', 'long']]\n",
    "gazeta_articles = gazeta_articles[gazeta_articles['title'].duplicated() == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before running below commands create sibling directory do analiza_mediow_pl 'my_roberta' with 'my_data' \n",
    "# and 'my_models' dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all data\n",
    "agora = [\" \"+x.replace('. ', ' . ').replace(', ', ' , ') for x in pd.concat([\n",
    "    gazeta_articles,\n",
    "    wyborcza_articles,\n",
    "]).astype(str).values.flatten()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Lider Konfederacji \"słuchał z zamkniętymi oczami\" . Korwin-Mikke: Ja nie spałem , wrzeszczałem z pięć razy',\n",
       " ' We wtorek w mediach pojawiły się zdjęcia z inauguracyjnego posiedzenia Sejmu IX kadencji . Uwagę przykuło zwłaszcza jedno - to , na którym Janusz Korwin-Mikke wygląda tak , jakby spał . Poseł Konfederacji Wolność i Niepodległość przekonuje , że wcale nie uciął sobie drzemki.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agora[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_end = int(0.03 * len(agora))\n",
    "valid_end = int(0.06 * len(agora))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "agora_test = agora[:test_end]\n",
    "agora_valid = agora[test_end:valid_end]\n",
    "agora_train = agora[valid_end:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/my_roberta/my_data/agora/agora.all.raw', 'w') as f:\n",
    "    f.write('\\n'.join(agora))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/my_roberta/my_data/agora.test.raw', 'w') as f:\n",
    "    f.write('\\n'.join(agora_test))\n",
    "with open('/my_roberta/my_data/agora.valid.raw', 'w') as f:\n",
    "    f.write('\\n'.join(agora_valid))\n",
    "with open('/my_roberta/my_data/agora.train.raw', 'w') as f:\n",
    "    f.write('\\n'.join(agora_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#             !!! Those commands run in my_roberta directory !!! #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode (copy paste to terminal, my_roberta dir)\n",
    "for SPLIT in train valid test; do \\\n",
    "    python -m examples.roberta.multiprocessing_bpe_encoder \\\n",
    "        --encoder-json '../analiza_mediow_pl/roberta_meta/encoder.json' \\\n",
    "        --vocab-bpe '../analiza_mediow_pl/roberta_meta/vocab.bpe' \\\n",
    "        --inputs my_data/agora.${SPLIT}.raw \\\n",
    "        --outputs my_data/agora.${SPLIT}.bpe \\\n",
    "        --keep-empty \\\n",
    "        --workers 60; \\\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binarize (copy paste to terminal, my_roberta dir)\n",
    "fairseq-preprocess \\\n",
    "    --only-source \\\n",
    "    --srcdict '/roberta/dict.txt' \\\n",
    "    --trainpref my_data/agora/agora.train.bpe \\\n",
    "    --validpref my_data/agora/agora.valid.bpe \\\n",
    "    --testpref my_data/agora/agora.test.bpe \\\n",
    "    --destdir data-bin/agora \\\n",
    "    --workers 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train (copy paste to terminal, my_doberta dir)\n",
    "fairseq-train --fp16 'data-bin/agora' \\\n",
    "    --task masked_lm --criterion masked_lm \\\n",
    "    --arch roberta_base --sample-break-mode complete --tokens-per-sample 512 \\\n",
    "    --optimizer adam --adam-betas '(0.9,0.98)' --adam-eps 1e-6 --clip-norm 0.0 \\\n",
    "    --lr-scheduler polynomial_decay --lr 0.0005 --warmup-updates 50 \\\n",
    "    --total-num-update 500000 \\\n",
    "    --dropout 0.1 --attention-dropout 0.1 --weight-decay 0.01 \\\n",
    "    --max-sentences 8 --update-freq 32 \\\n",
    "    --max-update 500000 --log-format simple --log-interval 1 \\\n",
    "    --restore-file '/roberta/checkpoint_best.pt' --skip-invalid-size-inputs-valid-test \\\n",
    "    --save-dir my_models/agora --min-lr 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cannot load model parameters from checkpoint /roberta/checkpoint_best.pt; please ensure that the architectures match."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download from https://github.com/sdadas/polish-nlp-resources/releases/download/roberta/roberta.zip\n",
    "# extract and place it above this repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base pl model trained on wikipedia \n",
    "model_path = \"/roberta\"\n",
    "loaded = hub_utils.from_pretrained(\n",
    "    model_name_or_path=model_path,\n",
    "    checkpoint_file=\"checkpoint_best.pt\",\n",
    "    data_name_or_path=model_path,\n",
    "    bpe=\"sentencepiece\",\n",
    "    sentencepiece_vocab=os.path.join(model_path, \"sentencepiece.model\"),\n",
    "    load_checkpoint_heads=True,\n",
    "    archive_map=RobertaModel.hub_models(),\n",
    "    cpu=True\n",
    ")\n",
    "roberta = RobertaHubInterface(loaded['args'], loaded['task'], loaded['models'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Bolesław chrobry urodził się w Krakowie.',\n",
       "  0.16482116281986237,\n",
       "  ' Krakowie')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta.fill_mask('Bolesław chrobry urodził się w <mask>.', topk = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my\n",
    "model_path = \"/roberta\"\n",
    "loaded = hub_utils.from_pretrained(\n",
    "    model_name_or_path=\"/my_roberta/my_models/agora\",\n",
    "    checkpoint_file=\"checkpoint169.pt\",\n",
    "    data_name_or_path=\"/my_roberta/data-bin/agora\",\n",
    "    bpe=\"sentencepiece\",\n",
    "    sentencepiece_vocab='/my_roberta/my_data/agora/agora.spm.model.model',\n",
    "    load_checkpoint_heads=True,\n",
    "    archive_map=RobertaModel.hub_models(),\n",
    "    cpu=True\n",
    ")\n",
    "agora_roberta = RobertaHubInterface(loaded['args'], loaded['task'], loaded['models'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check volatity\n",
    "def get_idx(res, word):\n",
    "    return res[res['word'] == ' '+word].index.values[0]\n",
    "def get_p(res, word):\n",
    "    return res[res['word'] == ' '+word]['p'].values[0]\n",
    "\n",
    "data_list = []\n",
    "sentence = 'Wiele można powiedzieć o Donaldzie Tusku, na pewno jest on jednak <mask> politykiem.'\n",
    "for i in range(150, 169):\n",
    "    loaded = hub_utils.from_pretrained(\n",
    "        model_name_or_path=\"/my_roberta/my_models/agora\",\n",
    "        checkpoint_file=\"checkpoint\"+str(i)+\".pt\",\n",
    "        data_name_or_path=\"/my_roberta/data-bin/agora\",\n",
    "        bpe=\"sentencepiece\",\n",
    "        sentencepiece_vocab='/my_roberta/my_data/agora/agora.spm.model.model',\n",
    "        load_checkpoint_heads=True,\n",
    "        archive_map=RobertaModel.hub_models(),\n",
    "        cpu=True\n",
    "    )\n",
    "    agora_roberta = RobertaHubInterface(loaded['args'], loaded['task'], loaded['models'][0])\n",
    "    res = pd.DataFrame(\n",
    "        agora_roberta.fill_mask(sentence, topk = 100),\n",
    "        columns = ['sentence', 'p', 'word']\n",
    "    )\n",
    "    try:\n",
    "        row = []\n",
    "        row.append(get_idx(res, 'dobrym'))\n",
    "        row.append(get_idx(res, 'złym'))\n",
    "        row.append(get_p(res, 'dobrym'))\n",
    "        row.append(get_p(res, 'złym'))\n",
    "        data_list.append(row)\n",
    "    except IndexError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_res = pd.DataFrame(data_list, columns = ['good_idx', 'bad_idx', 'good_p', 'bad_p'])\n",
    "final_res['score'] = final_res['good_p'] / (final_res['good_p']+final_res['bad_p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>good_idx</th>\n",
       "      <th>bad_idx</th>\n",
       "      <th>good_p</th>\n",
       "      <th>bad_p</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>0.063601</td>\n",
       "      <td>0.000893</td>\n",
       "      <td>0.986159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>0.071187</td>\n",
       "      <td>0.001517</td>\n",
       "      <td>0.979138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>96</td>\n",
       "      <td>0.022706</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.970992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>77</td>\n",
       "      <td>0.057736</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>0.980693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>77</td>\n",
       "      <td>0.017909</td>\n",
       "      <td>0.001108</td>\n",
       "      <td>0.941719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>78</td>\n",
       "      <td>0.069389</td>\n",
       "      <td>0.000919</td>\n",
       "      <td>0.986924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   good_idx  bad_idx    good_p     bad_p     score\n",
       "0         1       68  0.063601  0.000893  0.986159\n",
       "1         3       61  0.071187  0.001517  0.979138\n",
       "2         9       96  0.022706  0.000678  0.970992\n",
       "3         2       77  0.057736  0.001137  0.980693\n",
       "4        10       77  0.017909  0.001108  0.941719\n",
       "5         2       78  0.069389  0.000919  0.986924"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01695127480926457"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_res['score'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/google/sentencepiece\n",
    "# https://github.com/pytorch/fairseq/issues/1186"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make spm model\n",
    "spm_train \\\n",
    "    --input=my_data/agora/agora.all.raw \\\n",
    "    --model_prefix=my_data/agora/agora.spm.model \\\n",
    "    --vocab_size=50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode\n",
    "for SPLIT in train valid test; do \\\n",
    "    cat my_data/agora/agora.${SPLIT}.raw | \\\n",
    "    spm_encode --model=my_data/agora/agora.spm.model.model --output_format=piece > \\\n",
    "    my_data/agora/agora.${SPLIT}.bpe\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binarize \n",
    "fairseq-preprocess \\\n",
    "    --only-source \\\n",
    "    --trainpref my_data/agora/agora.train.bpe \\\n",
    "    --validpref my_data/agora/agora.valid.bpe \\\n",
    "    --testpref my_data/agora/agora.test.bpe \\\n",
    "    --destdir data-bin/agora \\\n",
    "    --workers 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fairseq-train --fp16 'data-bin/agora' \\\n",
    "    --task masked_lm --criterion masked_lm --encoder-layers 3\\\n",
    "    --arch roberta_base --sample-break-mode complete --tokens-per-sample 512 \\\n",
    "    --optimizer adam --adam-betas '(0.9,0.98)' --adam-eps 1e-6 --clip-norm 0.0 \\\n",
    "    --lr-scheduler polynomial_decay --lr 0.0001 --warmup-updates 0 \\\n",
    "    --total-num-update 500000 \\\n",
    "    --dropout 0.01 --attention-dropout 0.01 --weight-decay 0.01 \\\n",
    "    --max-sentences 8 --update-freq 64 \\\n",
    "    --max-update 500000 --log-format simple --log-interval 1 \\\n",
    "    --skip-invalid-size-inputs-valid-test \\\n",
    "    --save-dir my_models/agora --min-lr 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TVP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvp_articles = []\n",
    "for filename in listdir('data/tvp/articles'):\n",
    "    try:\n",
    "        tvp_articles.append(pd.read_csv('data/tvp/articles/'+filename, header = None))\n",
    "    except EmptyDataError:\n",
    "        pass # empty file\n",
    "tvp_articles = pd.concat(tvp_articles)\n",
    "tvp_articles.columns = ['title', 'short', 'long', 'img', 'com']\n",
    "tvp_articles = tvp_articles[['title', 'short', 'long']]\n",
    "tvp_articles = tvp_articles[tvp_articles['title'].duplicated() == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before running below commands create sibling directory do analiza_mediow_pl 'my_roberta' with 'my_data' \n",
    "# and 'my_models' dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all data\n",
    "tvp = [\" \"+x.replace('. ', ' . ').replace(', ', ' , ') \n",
    "         for x in tvp_articles.astype(str).values.flatten()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Macron straszy karami za nieprzyjmowanie migrantów',\n",
       " ' Za „poważnym karaniem” państw Unii , które odmawiają udziału w mechanizmie dystrybucji migrantów , opowiedział się Emmanuel Macron . Prezydent Francji spotkał się w Rzymie z premierem Włoch Giuseppem Contem.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvp[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_end = int(0.03 * len(tvp))\n",
    "valid_end = int(0.06 * len(tvp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvp_test = tvp[:test_end]\n",
    "tvp_valid = tvp[test_end:valid_end]\n",
    "tvp_train = tvp[valid_end:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/my_roberta/my_data/tvp/tvp.all.raw', 'w') as f:\n",
    "    f.write('\\n'.join(tvp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/my_roberta/my_data/tvp/tvp.test.raw', 'w') as f:\n",
    "    f.write('\\n'.join(tvp_test))\n",
    "with open('/my_roberta/my_data/tvp/tvp.valid.raw', 'w') as f:\n",
    "    f.write('\\n'.join(tvp_valid))\n",
    "with open('/my_roberta/my_data/tvp/tvp.train.raw', 'w') as f:\n",
    "    f.write('\\n'.join(tvp_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spm_train \\\n",
    "    --input=my_data/tvp/tvp.all.raw \\\n",
    "    --model_prefix=my_data/tvp/tvp.spm.model \\\n",
    "    --vocab_size=50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for SPLIT in train valid test; do \\\n",
    "    cat my_data/tvp/tvp.${SPLIT}.raw | \\\n",
    "    spm_encode --model=my_data/tvp/tvp.spm.model.model --output_format=piece > \\\n",
    "    my_data/tvp/tvp.${SPLIT}.bpe\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fairseq-preprocess \\\n",
    "    --only-source \\\n",
    "    --trainpref my_data/tvp/tvp.train.bpe \\\n",
    "    --validpref my_data/tvp/tvp.valid.bpe \\\n",
    "    --testpref my_data/tvp/tvp.test.bpe \\\n",
    "    --destdir data-bin/tvp \\\n",
    "    --workers 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fairseq-train --fp16 'data-bin/tvp' \\\n",
    "    --task masked_lm --criterion masked_lm --encoder-layers 3\\\n",
    "    --arch roberta_base --sample-break-mode complete --tokens-per-sample 512 \\\n",
    "    --optimizer adam --adam-betas '(0.9,0.98)' --adam-eps 1e-6 --clip-norm 0.0 \\\n",
    "    --lr-scheduler polynomial_decay --lr 0.0001 --warmup-updates 0 \\\n",
    "    --total-num-update 500000 \\\n",
    "    --dropout 0.01 --attention-dropout 0.01 --weight-decay 0.01 \\\n",
    "    --max-sentences 8 --update-freq 64 \\\n",
    "    --max-update 500000 --log-format simple --log-interval 1 \\\n",
    "    --skip-invalid-size-inputs-valid-test \\\n",
    "    --save-dir my_models/tvp --min-lr 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/roberta\"\n",
    "loaded = hub_utils.from_pretrained(\n",
    "    model_name_or_path=\"/my_roberta/my_models/tvp\",\n",
    "    checkpoint_file=\"checkpoint373.pt\",\n",
    "    data_name_or_path=\"/my_roberta/data-bin/tvp\",\n",
    "    bpe=\"sentencepiece\",\n",
    "    sentencepiece_vocab='/my_roberta/my_data/tvp/tvp.spm.model.model',\n",
    "    load_checkpoint_heads=True,\n",
    "    archive_map=RobertaModel.hub_models(),\n",
    "    cpu=True\n",
    ")\n",
    "tvp_roberta = RobertaHubInterface(loaded['args'], loaded['task'], loaded['models'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Aleksander Kwaśniewski to były polityk', 0.7797557711601257, ' były'),\n",
       " ('Aleksander Kwaśniewski to nie polityk', 0.07706533372402191, ' nie'),\n",
       " ('Aleksander Kwaśniewski to wybitny polityk',\n",
       "  0.01950007677078247,\n",
       "  ' wybitny'),\n",
       " ('Aleksander Kwaśniewski to lewicowy polityk',\n",
       "  0.011795088648796082,\n",
       "  ' lewicowy'),\n",
       " ('Aleksander Kwaśniewski to być polityk', 0.007840156555175781, ' być')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvp_roberta.fill_mask('Aleksander Kwaśniewski to <mask> polityk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
