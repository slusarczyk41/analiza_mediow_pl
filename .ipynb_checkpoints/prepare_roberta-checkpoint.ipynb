{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import listdir\n",
    "from pandas.errors import EmptyDataError\n",
    "from fairseq.models.roberta import RobertaModel, RobertaHubInterface\n",
    "from fairseq import hub_utils\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First prepare data (finally output of it will go to another folder, data is too large for github)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wyborcza_articles = []\n",
    "for filename in listdir('data/wyborcza/articles'):\n",
    "    try:\n",
    "        wyborcza_articles.append(pd.read_csv('data/wyborcza/articles/'+filename, header = None))\n",
    "    except EmptyDataError:\n",
    "        pass # empty file\n",
    "wyborcza_articles = pd.concat(wyborcza_articles)\n",
    "wyborcza_articles.columns = ['url', 'title', 'short', 'long', 'img', 'com']\n",
    "wyborcza_articles['short'] = wyborcza_articles['short'].str.replace(r'(.|..)\\n', '')\n",
    "wyborcza_articles = wyborcza_articles[~wyborcza_articles['long'].str.contains('W odpowiedzi do @', na = False) == True]\n",
    "wyborcza_articles = wyborcza_articles[['title', 'short', 'long']]\n",
    "wyborcza_articles = wyborcza_articles.dropna()\n",
    "wyborcza_articles = wyborcza_articles[wyborcza_articles['title'].duplicated() == False]\n",
    "wyborcza_articles = wyborcza_articles[wyborcza_articles['short'] != '0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gazeta_articles = []\n",
    "for filename in listdir('data/gazeta/articles'):\n",
    "    try:\n",
    "        gazeta_articles.append(pd.read_csv('data/gazeta/articles/'+filename, header = None))\n",
    "    except EmptyDataError:\n",
    "        pass # empty file\n",
    "gazeta_articles = pd.concat(gazeta_articles)\n",
    "gazeta_articles.columns = ['url', 'title', 'short', 'long', 'img', 'com']\n",
    "gazeta_articles = gazeta_articles[['title', 'short', 'long']]\n",
    "gazeta_articles = gazeta_articles[gazeta_articles['title'].duplicated() == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before running below commands create sibling directory do analiza_mediow_pl 'my_roberta' with 'my_data' \n",
    "# and 'my_models' dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all data\n",
    "agora = [\"\\n \"+x.replace('. ', ' . ').replace(', ', ' , ') for x in pd.concat([\n",
    "    gazeta_articles,\n",
    "    wyborcza_articles,\n",
    "]).astype(str).values.flatten()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n Lider Konfederacji \"słuchał z zamkniętymi oczami\" . Korwin-Mikke: Ja nie spałem , wrzeszczałem z pięć razy',\n",
       " '\\n We wtorek w mediach pojawiły się zdjęcia z inauguracyjnego posiedzenia Sejmu IX kadencji . Uwagę przykuło zwłaszcza jedno - to , na którym Janusz Korwin-Mikke wygląda tak , jakby spał . Poseł Konfederacji Wolność i Niepodległość przekonuje , że wcale nie uciął sobie drzemki.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agora[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_end = int(0.03 * len(agora))\n",
    "valid_end = int(0.06 * len(agora))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "agora_test = agora[:test_end]\n",
    "agora_valid = agora[test_end:valid_end]\n",
    "agora_train = agora[valid_end:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/my_roberta/my_data/agora/agora.all.raw', 'w') as f:\n",
    "    f.write('\\n'.join(agora))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../my_roberta/my_data/agora.test.raw', 'w') as f:\n",
    "    f.write('\\n'.join(agora_test))\n",
    "with open('../my_roberta/my_data/agora.valid.raw', 'w') as f:\n",
    "    f.write('\\n'.join(agora_valid))\n",
    "with open('../my_roberta/my_data/agora.train.raw', 'w') as f:\n",
    "    f.write('\\n'.join(agora_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#             !!! Those commands run in my_roberta directory !!! #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode (copy paste to terminal, my_roberta dir)\n",
    "for SPLIT in train valid test; do \\\n",
    "    python -m examples.roberta.multiprocessing_bpe_encoder \\\n",
    "        --encoder-json '../analiza_mediow_pl/roberta_meta/encoder.json' \\\n",
    "        --vocab-bpe '../analiza_mediow_pl/roberta_meta/vocab.bpe' \\\n",
    "        --inputs my_data/agora.${SPLIT}.raw \\\n",
    "        --outputs my_data/agora.${SPLIT}.bpe \\\n",
    "        --keep-empty \\\n",
    "        --workers 60; \\\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binarize (copy paste to terminal, my_roberta dir)\n",
    "fairseq-preprocess \\\n",
    "    --only-source \\\n",
    "    --srcdict '../analiza_mediow_pl/roberta_meta/dict.txt' \\\n",
    "    --trainpref my_data/agora.train.bpe \\\n",
    "    --validpref my_data/agora.valid.bpe \\\n",
    "    --testpref my_data/agora.test.bpe \\\n",
    "    --destdir data-bin/agora \\\n",
    "    --workers 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train (copy paste to terminal, my_doberta dir)\n",
    "fairseq-train --fp16 'data-bin/agora' \\\n",
    "    --task masked_lm --criterion masked_lm \\\n",
    "    --arch roberta_base --sample-break-mode complete --tokens-per-sample 512 \\\n",
    "    --optimizer adam --adam-betas '(0.9,0.98)' --adam-eps 1e-6 --clip-norm 0.0 \\\n",
    "    --lr-scheduler polynomial_decay --lr 0.0005 --warmup-updates 50 \\\n",
    "    --total-num-update 500 \\\n",
    "    --dropout 0.1 --attention-dropout 0.1 --weight-decay 0.01 \\\n",
    "    --max-sentences 8 --update-freq 32 \\\n",
    "    --max-update 500 --log-format simple --log-interval 1 \\\n",
    "    --restore-file '/roberta/checkpoint_best.pt' --skip-invalid-size-inputs-valid-test \\\n",
    "    --save-dir my_models/agora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cannot load model parameters from checkpoint /roberta/checkpoint_best.pt; please ensure that the architectures match."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download from https://github.com/sdadas/polish-nlp-resources/releases/download/roberta/roberta.zip\n",
    "# extract and place it above this repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base pl model trained on wikipedia \n",
    "model_path = \"/roberta\"\n",
    "loaded = hub_utils.from_pretrained(\n",
    "    model_name_or_path=model_path,\n",
    "    checkpoint_file=\"checkpoint_best.pt\",\n",
    "    data_name_or_path=model_path,\n",
    "    bpe=\"sentencepiece\",\n",
    "    sentencepiece_vocab=os.path.join(model_path, \"sentencepiece.model\"),\n",
    "    load_checkpoint_heads=True,\n",
    "    archive_map=RobertaModel.hub_models(),\n",
    "    cpu=True\n",
    ")\n",
    "roberta = RobertaHubInterface(loaded['args'], loaded['task'], loaded['models'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Bolesław chrobry urodził się w Krakowie.',\n",
       "  0.16482116281986237,\n",
       "  ' Krakowie')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta.fill_mask('Bolesław chrobry urodził się w <mask>.', topk = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my\n",
    "model_path = \"/roberta\"\n",
    "loaded = hub_utils.from_pretrained(\n",
    "    model_name_or_path=\"/my_roberta/my_models/agora\",\n",
    "    checkpoint_file=\"checkpoint_best.pt\",\n",
    "    data_name_or_path=\"/my_roberta/data-bin/agora\",\n",
    "    bpe=\"sentencepiece\",\n",
    "    sentencepiece_vocab='/my_roberta/my_data/agora/agora.spm.model.model',\n",
    "    load_checkpoint_heads=True,\n",
    "    archive_map=RobertaModel.hub_models(),\n",
    "    cpu=True\n",
    ")\n",
    "agora_roberta = RobertaHubInterface(loaded['args'], loaded['task'], loaded['models'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my model\n",
    "#agora_roberta = RobertaModel.from_pretrained('/my_roberta/my_models/agora', 'checkpoint_best.pt', '/my_roberta/data-bin/agora/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Bolesław chrobry urodził się w..', 0.05014575272798538, '.'),\n",
       " ('Bolesław chrobry urodził się w,.', 0.04615228623151779, ','),\n",
       " ('Bolesław chrobry urodził się w w.', 0.02777603454887867, ' w'),\n",
       " ('Bolesław chrobry urodził się w na.', 0.022864116355776787, ' na'),\n",
       " ('Bolesław chrobry urodził się w i.', 0.01340454164892435, ' i'),\n",
       " ('Bolesław chrobry urodził się w z.', 0.013038057833909988, ' z'),\n",
       " ('Bolesław chrobry urodził się w się.', 0.012881123460829258, ' się'),\n",
       " ('Bolesław chrobry urodził się wa.', 0.010829989798367023, 'a'),\n",
       " ('Bolesław chrobry urodził się w -.', 0.010078019462525845, ' -')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agora_roberta.fill_mask('Bolesław chrobry urodził się w <mask>.', topk = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Polska jest.', 0.05014567822217941, '.'),\n",
       " ('Polska jest,', 0.046152062714099884, ','),\n",
       " ('Polska jest w', 0.027776073664426804, ' w'),\n",
       " ('Polska jest na', 0.0228640828281641, ' na'),\n",
       " ('Polska jest i', 0.013404502533376217, ' i'),\n",
       " ('Polska jest z', 0.013038032688200474, ' z'),\n",
       " ('Polska jest się', 0.012881110422313213, ' się'),\n",
       " ('Polska jesta', 0.010829963721334934, 'a'),\n",
       " ('Polska jest -', 0.010077985003590584, ' -')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agora_roberta.fill_mask('Polska jest<mask>', topk = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/google/sentencepiece\n",
    "# https://github.com/pytorch/fairseq/issues/1186"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make spm model\n",
    "spm_train \\\n",
    "    --input=my_data/agora/agora.all.raw \\\n",
    "    --model_prefix=my_data/agora/agora.spm.model \\\n",
    "    --vocab_size=50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode\n",
    "for SPLIT in train valid test; do \\\n",
    "    cat my_data/agora/agora.${SPLIT}.raw | \\\n",
    "    spm_encode --model=my_data/agora/agora.spm.model.model --output_format=piece > \\\n",
    "    my_data/agora/agora.${SPLIT}.bpe\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binarize \n",
    "fairseq-preprocess \\\n",
    "    --only-source \\\n",
    "    --trainpref my_data/agora/agora.train.bpe \\\n",
    "    --validpref my_data/agora/agora.valid.bpe \\\n",
    "    --testpref my_data/agora/agora.test.bpe \\\n",
    "    --destdir data-bin/agora \\\n",
    "    --workers 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
