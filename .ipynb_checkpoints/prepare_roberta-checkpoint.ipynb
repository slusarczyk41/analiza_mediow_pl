{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import listdir\n",
    "from pandas.errors import EmptyDataError\n",
    "from fairseq.models.roberta import RobertaModel, RobertaHubInterface\n",
    "from fairseq import hub_utils\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First prepare data (finally output of it will go to another folder, data is too large for github)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wyborcza_articles = []\n",
    "for filename in listdir('data/wyborcza/articles'):\n",
    "    try:\n",
    "        wyborcza_articles.append(pd.read_csv('data/wyborcza/articles/'+filename, header = None))\n",
    "    except EmptyDataError:\n",
    "        pass # empty file\n",
    "wyborcza_articles = pd.concat(wyborcza_articles)\n",
    "wyborcza_articles.columns = ['url', 'title', 'short', 'long', 'img', 'com']\n",
    "wyborcza_articles['short'] = wyborcza_articles['short'].str.replace(r'(.|..)\\n', '')\n",
    "wyborcza_articles = wyborcza_articles[~wyborcza_articles['long'].str.contains('W odpowiedzi do @', na = False) == True]\n",
    "wyborcza_articles = wyborcza_articles[['title', 'short', 'long']]\n",
    "wyborcza_articles = wyborcza_articles.dropna()\n",
    "wyborcza_articles = wyborcza_articles[wyborcza_articles['title'].duplicated() == False]\n",
    "wyborcza_articles = wyborcza_articles[wyborcza_articles['short'] != '0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gazeta_articles = []\n",
    "for filename in listdir('data/gazeta/articles'):\n",
    "    try:\n",
    "        gazeta_articles.append(pd.read_csv('data/gazeta/articles/'+filename, header = None))\n",
    "    except EmptyDataError:\n",
    "        pass # empty file\n",
    "gazeta_articles = pd.concat(gazeta_articles)\n",
    "gazeta_articles.columns = ['url', 'title', 'short', 'long', 'img', 'com']\n",
    "gazeta_articles = gazeta_articles[['title', 'short', 'long']]\n",
    "gazeta_articles = gazeta_articles[gazeta_articles['title'].duplicated() == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before running below commands create sibling directory do analiza_mediow_pl 'my_roberta' with 'my_data' \n",
    "# and 'my_models' dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all data\n",
    "agora = pd.concat([\n",
    "    gazeta_articles,\n",
    "    wyborcza_articles,\n",
    "]).astype(str).values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Lider Konfederacji \"słuchał z zamkniętymi oczami\". Korwin-Mikke: Ja nie spałem, wrzeszczałem z pięć razy',\n",
       "       'We wtorek w mediach pojawiły się zdjęcia z inauguracyjnego posiedzenia Sejmu IX kadencji. Uwagę przykuło zwłaszcza jedno - to, na którym Janusz Korwin-Mikke wygląda tak, jakby spał. Poseł Konfederacji Wolność i Niepodległość przekonuje, że wcale nie uciął sobie drzemki.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agora[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_end = int(0.03 * len(agora))\n",
    "valid_end = int(0.06 * len(agora))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "agora_test = agora[:test_end]\n",
    "agora_valid = agora[test_end:valid_end]\n",
    "agora_train = agora[valid_end:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../my_roberta/my_data/agora.test.raw', 'w') as f:\n",
    "    f.write('\\n'.join(agora_test))\n",
    "with open('../my_roberta/my_data/agora.valid.raw', 'w') as f:\n",
    "    f.write('\\n'.join(agora_valid))\n",
    "with open('../my_roberta/my_data/agora.train.raw', 'w') as f:\n",
    "    f.write('\\n'.join(agora_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#             !!! Those commands run in my_roberta directory !!! #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode (copy paste to terminal, my_roberta dir)\n",
    "for SPLIT in train valid test; do \\\n",
    "    python -m examples.roberta.multiprocessing_bpe_encoder \\\n",
    "        --encoder-json '../analiza_mediow_pl/roberta_meta/encoder.json' \\\n",
    "        --vocab-bpe '../analiza_mediow_pl/roberta_meta/vocab.bpe' \\\n",
    "        --inputs my_data/agora.${SPLIT}.raw \\\n",
    "        --outputs my_data/agora.${SPLIT}.bpe \\\n",
    "        --keep-empty \\\n",
    "        --workers 60; \\\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binarize (copy paste to terminal, my_roberta dir)\n",
    "fairseq-preprocess \\\n",
    "    --only-source \\\n",
    "    --srcdict '../analiza_mediow_pl/roberta_meta/dict.txt' \\\n",
    "    --trainpref my_data/agora.train.bpe \\\n",
    "    --validpref my_data/agora.valid.bpe \\\n",
    "    --testpref my_data/agora.test.bpe \\\n",
    "    --destdir data-bin/agora \\\n",
    "    --workers 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train (copy paste to terminal, my_doberta dir)\n",
    "fairseq-train --fp16 'data-bin/agora' \\\n",
    "    --task masked_lm --criterion masked_lm \\\n",
    "    --arch roberta_base --sample-break-mode complete --tokens-per-sample 512 \\\n",
    "    --optimizer adam --adam-betas '(0.9,0.98)' --adam-eps 1e-6 --clip-norm 0.0 \\\n",
    "    --lr-scheduler polynomial_decay --lr 0.0005 --warmup-updates 50 \\\n",
    "    --total-num-update 500 \\\n",
    "    --dropout 0.1 --attention-dropout 0.1 --weight-decay 0.01 \\\n",
    "    --max-sentences 8 --update-freq 32 \\\n",
    "    --max-update 500 --log-format simple --log-interval 1 \\\n",
    "    --restore-file roberta --skip-invalid-size-inputs-valid-test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download from https://github.com/sdadas/polish-nlp-resources/releases/download/roberta/roberta.zip\n",
    "# extract and place it above this repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base pl model trained on wikipedia \n",
    "model_path = \"/roberta\"\n",
    "loaded = hub_utils.from_pretrained(\n",
    "    model_name_or_path=model_path,\n",
    "    checkpoint_file=\"checkpoint_best.pt\",\n",
    "    data_name_or_path=model_path,\n",
    "    bpe=\"sentencepiece\",\n",
    "    sentencepiece_vocab=os.path.join(model_path, \"sentencepiece.model\"),\n",
    "    load_checkpoint_heads=True,\n",
    "    archive_map=RobertaModel.hub_models(),\n",
    "    cpu=True\n",
    ")\n",
    "roberta = RobertaHubInterface(loaded['args'], loaded['task'], loaded['models'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Bolesław chrobry urodził się w Krakowie.',\n",
       "  0.16482116281986237,\n",
       "  ' Krakowie')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta.fill_mask('Bolesław chrobry urodził się w <mask>.', topk = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1042301B [00:00, 1496394.07B/s]\n",
      "456318B [00:00, 639821.92B/s]\n"
     ]
    }
   ],
   "source": [
    "# my model\n",
    "agora_roberta = RobertaModel.from_pretrained('/my_roberta/checkpoints', 'checkpoint_best.pt', '/my_roberta/my_data/agora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Bolesław chrobry urodził się w <unk>.', 0.7465916872024536, '<unk>'),\n",
       " ('Bolesław chrobry urodził się w �.', 0.03076404519379139, '�'),\n",
       " ('Bolesław chrobry urodził się w z.', 0.024779153987765312, 'z'),\n",
       " ('Bolesław chrobry urodził się w ..', 0.02005680277943611, '.'),\n",
       " ('Bolesław chrobry urodził się w ,.', 0.01749323680996895, ','),\n",
       " ('Bolesław chrobry urodził się w j.', 0.013219810090959072, 'j'),\n",
       " ('Bolesław chrobry urodził się w y.', 0.012879307381808758, 'y'),\n",
       " ('Bolesław chrobry urodził się w �.', 0.01143086701631546, '�'),\n",
       " ('Bolesław chrobry urodził się w w.', 0.011288624256849289, 'w')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agora_roberta.fill_mask('Bolesław chrobry urodził się w  <mask>.', topk = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Polska jest <unk>', 0.74659264087677, '<unk>'),\n",
       " ('Polska jest �', 0.03076387755572796, '�'),\n",
       " ('Polska jest z', 0.02477909065783024, 'z'),\n",
       " ('Polska jest .', 0.020056752488017082, '.'),\n",
       " ('Polska jest ,', 0.01749320887029171, ','),\n",
       " ('Polska jest j', 0.013219725340604782, 'j'),\n",
       " ('Polska jest y', 0.012879274785518646, 'y'),\n",
       " ('Polska jest �', 0.011430815793573856, '�'),\n",
       " ('Polska jest w', 0.01128859631717205, 'w')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agora_roberta.fill_mask('Polska jest  <mask>', topk = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
